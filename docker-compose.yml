version: "2"
services:

  zookeeper2:
    image: confluentinc/cp-zookeeper:5.1.2
    hostname: zookeeper2
    container_name: zookeeper2
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka2:
    image: confluentinc/cp-kafka:5.1.2
    hostname: kafka2
    container_name: kafka2
    depends_on:
      - zookeeper2
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper2:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092,PLAINTEXT_HOST://localhost:29092
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1


  elasticsearch2:
    container_name: elasticsearch2
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2
    ports:
      - '9200:9200'
      - '9300:9300'
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - 'ES_JAVA_OPTS=-Xms512m -Xmx512m'
      - cluster.routing.allocation.disk.threshold_enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    #old
    #environment:  
    #  - cluster.name=docker-cluster
    #  - bootstrap.memory_lock=true
    #  - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    #ulimits:
    #  memlock:
    #    soft: -1
    #    hard: -1
    #ports:
    #  - '9200:9200'
    #  - '9300:9300'
    
  kibana2:
  #old
  #  container_name: kibana
  #  image: docker.elastic.co/kibana/kibana:6.6.2
  #  ports:
  #    - '5601:5601'
  #  depends_on:
  #    - elasticsearch
  #  environment:
  #    SERVER_NAME: kibana.example.org
  #    ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    container_name: kibana2
    image: docker.elastic.co/kibana/kibana:7.10.2
    ports:
      - '5601:5601'
    depends_on:
      - elasticsearch2
    environment:
      SERVER_NAME: kibana.example.org
      ELASTICSEARCH_HOSTS: '["http://elasticsearch2:9200"]'

  kafka-connect2:
    image: confluentinc/cp-kafka-connect:5.4.9
    platform: linux/amd64
    container_name: kafka-connect2
    ports:
      - '8083:8083'
    depends_on:
      - zookeeper2
      - kafka2
      - elasticsearch2
    volumes:
      - $PWD/connect-plugins:/connect-plugins
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka2:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: 'connect'
      CONNECT_CONFIG_STORAGE_TOPIC: connect-config
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_REPLICATION_FACTOR: 1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      # CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: 'false'
      CONNECT_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: 'false'
      # CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: 'io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor'
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: 'io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor'
      CONNECT_REST_ADVERTISED_HOST_NAME: 'connect'
      CONNECT_ZOOKEEPER_CONNECT: zookeeper2:2181
      # CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components
      CONNECT_PLUGIN_PATH: /connect-plugins
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_LOG4J_LOGGERS: org.reflections=ERROR
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-3.3.0.jar
  ksqldb2:
    image: confluentinc/ksqldb-server:0.15.0
    hostname: ksqldb2
    container_name: ksqldb2
    depends_on:
      - kafka2
      - kafka-connect2
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka2:9092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_CONNECT_URL: http://kafka-connect2:8083
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry2:8081
      KSQL_KSQL_SERVICE_ID: confluent_rmoff_01
      KSQL_KSQL_HIDDEN_TOPICS: '^_.*'

  schema-registry2:
    image: confluentinc/cp-schema-registry:6.1.0
    container_name: schema-registry2
    depends_on:
      - zookeeper2
      - kafka2
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry2
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka2:9092

  flaskapp2:
    build: .
    container_name: flask_dev2
    ports:
      - '5000:5000'
    volumes:
      - .:/app
  
  kafkacat2:
    image: edenhill/kafkacat:1.7.0-PRE1
    container_name: kafkacat2
    entrypoint: 
      - /bin/sh 
      - -c 
      - |
        apk add jq; 
        while [ 1 -eq 1 ];do sleep 60;done
  nginx:
    image: nginx
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
      - ./key.pem:/root/ssl/key.pem
      - ./cert.pem:/root/ssl/cert.pem
    ports:
      - "443:443"
    depends_on:
      - flaskapp2